{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A28 loaded\n",
      "IP18c loaded\n",
      "IS6a loaded\n",
      "IS10abcde loaded\n",
      "E8a loaded\n",
      "B30 loaded\n",
      "A6a loaded\n",
      "P3 loaded\n",
      "IP27a loaded\n",
      "B16 loaded\n",
      "Z4b loaded\n",
      "IJ4a loaded\n",
      "B17 loaded\n",
      "IS9abcde loaded\n",
      "IP3 loaded\n",
      "IJ13 loaded\n",
      "B8 loaded\n",
      "IP25a loaded\n",
      "E3ab loaded\n",
      "E1 loaded\n",
      "IJ9 loaded\n",
      "A15 loaded\n",
      "IS19bd loaded\n",
      "IJ4b loaded\n",
      "E2c loaded\n",
      "C8b loaded\n",
      "C11a loaded\n",
      "G4 loaded\n",
      "A3 loaded\n",
      "A25 loaded\n",
      "E7a loaded\n",
      "IP31a loaded\n",
      "IP20a loaded\n",
      "IJ14c loaded\n",
      "A23 loaded\n",
      "C4c loaded\n",
      "IJ11a loaded\n",
      "IJ3 loaded\n",
      "IP28a loaded\n",
      "C7a loaded\n",
      "A7b loaded\n",
      "IP15b loaded\n",
      "B22a loaded\n",
      "C7b loaded\n",
      "IJ1 loaded\n",
      "B7 loaded\n",
      "IS16bcd loaded\n",
      "IS4bd loaded\n",
      "B26 loaded\n",
      "E10 loaded\n",
      "A24 loaded\n",
      "C2e loaded\n",
      "IJ4cde loaded\n",
      "A31b loaded\n",
      "B24b loaded\n",
      "A14 loaded\n",
      "B34 loaded\n",
      "C2a loaded\n",
      "C6a loaded\n",
      "IJ12 loaded\n",
      "E4 loaded\n",
      "Z9 loaded\n",
      "IS22abcdef loaded\n",
      "C1 loaded\n",
      "C4b loaded\n",
      "IS12a loaded\n",
      "A8 loaded\n",
      "A29 loaded\n",
      "IP6 loaded\n",
      "A16 loaded\n",
      "IP9 loaded\n",
      "IP14a loaded\n",
      "IS8ab loaded\n",
      "B33 loaded\n",
      "IP26a loaded\n",
      "IS20 loaded\n",
      "C6b loaded\n",
      "C8a loaded\n",
      "A5a loaded\n",
      "P2 loaded\n",
      "E8e loaded\n",
      "IJ14a loaded\n",
      "IP28 loaded\n",
      "B9 loaded\n",
      "C5a loaded\n",
      "IS15b loaded\n",
      "Z3 loaded\n",
      "loading total_data_CNN03/Z3/Z3_id24215_ff15955-131030_00104652.jpg failed\n",
      "A20 loaded\n",
      "IS23 loaded\n",
      "IP22 loaded\n",
      "B12 loaded\n",
      "C13a loaded\n",
      "IS1ac loaded\n",
      "C13b loaded\n",
      "IS7ab loaded\n",
      "A2b loaded\n",
      "IS16a loaded\n",
      "A9 loaded\n",
      "B20b loaded\n",
      "E9 loaded\n",
      "A12 loaded\n",
      "IP27b loaded\n",
      "A32a loaded\n",
      "IS12c loaded\n",
      "IS11b loaded\n",
      "IS11a loaded\n",
      "I1 loaded\n",
      "IP20b loaded\n",
      "IP10a loaded\n",
      "C9b loaded\n",
      "IP30 loaded\n",
      "G5 loaded\n",
      "B6 loaded\n",
      "IP1b loaded\n",
      "X1 loaded\n",
      "B28 loaded\n",
      "IS3bd loaded\n",
      "C10b loaded\n",
      "C5b loaded\n",
      "IS6bcdefg loaded\n",
      "IS11d loaded\n",
      "IP24 loaded\n",
      "C2f loaded\n",
      "C14a loaded\n",
      "P7 loaded\n",
      "A4 loaded\n",
      "C10a loaded\n",
      "B24a loaded\n",
      "IS15a loaded\n",
      "B23a loaded\n",
      "A13 loaded\n",
      "IP5 loaded\n",
      "P6 loaded\n",
      "A6b loaded\n",
      "A18 loaded\n",
      "B10 loaded\n",
      "Z4e loaded\n",
      "Z4a loaded\n",
      "C11b loaded\n",
      "B1 loaded\n",
      "C12b loaded\n",
      "IP25b loaded\n",
      "IP4a loaded\n",
      "IJ11b loaded\n",
      "IP8a loaded\n",
      "IP8b loaded\n",
      "B3a loaded\n",
      "IS18b loaded\n",
      "IS5 loaded\n",
      "B18 loaded\n",
      "IS17 loaded\n",
      "B11 loaded\n",
      "B21a loaded\n",
      "B19 loaded\n",
      "A2a loaded\n",
      "IJ8 loaded\n",
      "IS2ac loaded\n",
      "IJ5 loaded\n",
      "A1b loaded\n",
      "X2 loaded\n",
      "A26 loaded\n",
      "A1a loaded\n",
      "C4a loaded\n",
      "B27 loaded\n",
      "A27 loaded\n",
      "G2 loaded\n",
      "A5b loaded\n",
      "IJ6 loaded\n",
      "B20a loaded\n",
      "IP19 loaded\n",
      "B21b loaded\n",
      "IP7 loaded\n",
      "IP21 loaded\n",
      "IS13 loaded\n",
      "B13 loaded\n",
      "P4 loaded\n",
      "IS4ac loaded\n",
      "IS18a loaded\n",
      "A17 loaded\n",
      "C3b loaded\n",
      "IP15a loaded\n",
      "B2 loaded\n",
      "B5 loaded\n",
      "IS2bd loaded\n",
      "IP11x1213abc loaded\n",
      "G3 loaded\n",
      "E11 loaded\n",
      "B3b loaded\n",
      "IP2 loaded\n",
      "B15 loaded\n",
      "A32b loaded\n",
      "IS19ac loaded\n",
      "A21 loaded\n",
      "IS24abc loaded\n",
      "C9a loaded\n",
      "E8c loaded\n",
      "B32 loaded\n",
      "IP14b loaded\n",
      "A7a loaded\n",
      "E7b loaded\n",
      "IP16 loaded\n",
      "E5 loaded\n",
      "B31 loaded\n",
      "C3a loaded\n",
      "B25 loaded\n",
      "P8 loaded\n",
      "IP13d loaded\n",
      "IP10b loaded\n",
      "A19 loaded\n",
      "B4 loaded\n",
      "B29 loaded\n",
      "P1 loaded\n",
      "A31c loaded\n",
      "IP18b loaded\n",
      "IP23b loaded\n",
      "A31a loaded\n",
      "IJ2 loaded\n",
      "C14b loaded\n",
      "IJ15 loaded\n",
      "IP1a loaded\n",
      "G1 loaded\n",
      "IS1bd loaded\n",
      "IJ14b loaded\n",
      "IS21abcd loaded\n",
      "IS11c loaded\n",
      "IP26b loaded\n",
      "IP17 loaded\n",
      "IS3ac loaded\n",
      "IS14 loaded\n",
      "E13 loaded\n",
      "Z5d loaded\n",
      "B14 loaded\n",
      "E6 loaded\n",
      "IJ10 loaded\n",
      "C12a loaded\n",
      "E8d loaded\n",
      "X3 loaded\n",
      "C2c loaded\n",
      "Z4c loaded\n",
      "IJ7 loaded\n",
      "A11 loaded\n",
      "IP4b loaded\n",
      "C2b loaded\n",
      "IS12b loaded\n",
      "A22 loaded\n",
      "A30 loaded\n",
      "E8b loaded\n",
      "E2d loaded\n",
      "A10 loaded\n",
      "E2ab loaded\n",
      "IP18a loaded\n",
      "B23b loaded\n",
      "B22b loaded\n",
      "C2d loaded\n",
      "labels: ['A28', 'IP18c', 'IS6a', 'IS10abcde', 'E8a', 'B30', 'A6a', 'P3', 'IP27a', 'B16', 'Z4b', 'IJ4a', 'B17', 'IS9abcde', 'IP3', 'IJ13', 'B8', 'IP25a', 'E3ab', 'E1', 'IJ9', 'A15', 'IS19bd', 'IJ4b', 'E2c', 'C8b', 'C11a', 'G4', 'A3', 'A25', 'E7a', 'IP31a', 'IP20a', 'IJ14c', 'A23', 'C4c', 'IJ11a', 'IJ3', 'IP28a', 'C7a', 'A7b', 'IP15b', 'B22a', 'C7b', 'IJ1', 'B7', 'IS16bcd', 'IS4bd', 'B26', 'E10', 'A24', 'C2e', 'IJ4cde', 'A31b', 'B24b', 'A14', 'B34', 'C2a', 'C6a', 'IJ12', 'E4', 'Z9', 'IS22abcdef', 'C1', 'C4b', 'IS12a', 'A8', 'A29', 'IP6', 'A16', 'IP9', 'IP14a', 'IS8ab', 'B33', 'IP26a', 'IS20', 'C6b', 'C8a', 'A5a', 'P2', 'E8e', 'IJ14a', 'IP28', 'B9', 'C5a', 'IS15b', 'Z3', 'A20', 'IS23', 'IP22', 'B12', 'C13a', 'IS1ac', 'C13b', 'IS7ab', 'A2b', 'IS16a', 'A9', 'B20b', 'E9', 'A12', 'IP27b', 'A32a', 'IS12c', 'IS11b', 'IS11a', 'I1', 'IP20b', 'IP10a', 'C9b', 'IP30', 'G5', 'B6', 'IP1b', 'X1', 'B28', 'IS3bd', 'C10b', 'C5b', 'IS6bcdefg', 'IS11d', 'IP24', 'C2f', 'C14a', 'P7', 'A4', 'C10a', 'B24a', 'IS15a', 'B23a', 'A13', 'IP5', 'P6', 'A6b', 'A18', 'B10', 'Z4e', 'Z4a', 'C11b', 'B1', 'C12b', 'IP25b', 'IP4a', 'IJ11b', 'IP8a', 'IP8b', 'B3a', 'IS18b', 'IS5', 'B18', 'IS17', 'B11', 'B21a', 'B19', 'A2a', 'IJ8', 'IS2ac', 'IJ5', 'A1b', 'X2', 'A26', 'A1a', 'C4a', 'B27', 'A27', 'G2', 'A5b', 'IJ6', 'B20a', 'IP19', 'B21b', 'IP7', 'IP21', 'IS13', 'B13', 'P4', 'IS4ac', 'IS18a', 'A17', 'C3b', 'IP15a', 'B2', 'B5', 'IS2bd', 'IP11x1213abc', 'G3', 'E11', 'B3b', 'IP2', 'B15', 'A32b', 'IS19ac', 'A21', 'IS24abc', 'C9a', 'E8c', 'B32', 'IP14b', 'A7a', 'E7b', 'IP16', 'E5', 'B31', 'C3a', 'B25', 'P8', 'IP13d', 'IP10b', 'A19', 'B4', 'B29', 'P1', 'A31c', 'IP18b', 'IP23b', 'A31a', 'IJ2', 'C14b', 'IJ15', 'IP1a', 'G1', 'IS1bd', 'IJ14b', 'IS21abcd', 'IS11c', 'IP26b', 'IP17', 'IS3ac', 'IS14', 'E13', 'Z5d', 'B14', 'E6', 'IJ10', 'C12a', 'E8d', 'X3', 'C2c', 'Z4c', 'IJ7', 'A11', 'IP4b', 'C2b', 'IS12b', 'A22', 'A30', 'E8b', 'E2d', 'A10', 'E2ab', 'IP18a', 'B23b', 'B22b', 'C2d']\n",
      "Dataset of 27070 images loaded\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from train import TrainingExperiment\n",
    "from dataset import build_dataset_out_of_dir_structure, get_data_loaders\n",
    "from models import Model1Vgg19, ModelTinyHruz\n",
    "\n",
    "\n",
    "\n",
    "IMG_DIR = 'total_data_CNN03'\n",
    "\n",
    "# load dataset to memory\n",
    "imgs, labls, labls_2_id = build_dataset_out_of_dir_structure(Path(IMG_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split; train:21656, test:2707, val:2707\n"
     ]
    }
   ],
   "source": [
    "RESIZE_TO = (128,128)\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# dataloaders\n",
    "train_data, test_data, val_data = get_data_loaders(imgs, labls, labls_2_id, \n",
    "                                                   batch_size=BATCH_SIZE, resize_to=RESIZE_TO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training of ModelTinyHruz(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc4): Linear(in_features=1465472, out_features=254, bias=True)\n",
      "), using device cuda:0\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/tomas/miniconda3/envs/mmdet/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "5414it [15:32,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 15327.98540968135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "677it [00:30, 22.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 682.0162502578169\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.39 GiB (GPU 0; 3.94 GiB total capacity; 1.74 GiB already allocated; 465.88 MiB free; 2.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m)\n\u001b[1;32m      6\u001b[0m tr \u001b[38;5;241m=\u001b[39m TrainingExperiment(net, loss, train_data, val_data\u001b[38;5;241m=\u001b[39mval_data)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m tr\u001b[38;5;241m.\u001b[39mplot_loss()\n",
      "File \u001b[0;32m~/traffic-signs-features/train.py:69\u001b[0m, in \u001b[0;36mTrainingExperiment.train\u001b[0;34m(self, optimizer, num_epoch)\u001b[0m\n\u001b[1;32m     67\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(out, labels)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# else: #get accuracy on validation\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#     pred = torch.argmax(out,1)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#     acc = torch.sum(pred == labels)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#     val_acc += acc.item() \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.39 GiB (GPU 0; 3.94 GiB total capacity; 1.74 GiB already allocated; 465.88 MiB free; 2.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "net = ModelTinyHruz(num_out_classes=len(labls_2_id), img_size=RESIZE_TO)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.002)\n",
    "\n",
    "tr = TrainingExperiment(net, loss, train_data, val_data=val_data)\n",
    "tr.train(optimizer, 10)\n",
    "tr.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
